% Setup -------------------------------

\documentclass[a4paper]{report}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\usepackage{hyperref}
\usepackage{indentfirst}

\usepackage{fancyvrb}
\usepackage{xcolor}

\usepackage{graphicx}

% Encoding
%--------------------------------------
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
%--------------------------------------

% Portuguese-specific commands
%--------------------------------------
\usepackage[portuguese]{babel}
%--------------------------------------

% Hyphenation rules
%--------------------------------------
\usepackage{hyphenat}
%--------------------------------------

% Capa do relatório

\title{
	Gestão de Grandes Conjuntos de Dados
	\\ \Large{\textbf{1º Trabalho Prático}}
	\\ -
	\\ Mestrado em Engenharia Informática
	\\ Universidade do Minho
}
\author{
	\begin{tabular}{ll}
		\textbf{Grupo nº 8}
		\\
		\hline
		PG41080 & João Ribeiro Imperadeiro
        \\
		PG41081 & José Alberto Martins Boticas
		\\
        PG41091 & Nelson José Dias Teixeira
        \\
        PG41851 & Rui Miguel da Costa Meira
	\end{tabular}
}

\date{\today}

\begin{document}

\begin{titlepage}
    \maketitle
\end{titlepage}

% Índice

\tableofcontents
\listoffigures

% Introdução

\chapter{Introdução} \label{intro}
\large {
	Na primeira parte deste trabalho prático é requerida a concretização e avaliação experimental de tarefas de armazenamento e processamento de dados utilizando as ferramentas computacionais \textit{Hadoop HDFS}, \textit{HBase} e, ainda, o paradigma \textit{MapReduce}. 
	Por forma a realizar estas tarefas, os dados a utilizar para tal efeito correspondem ao conjunto de dados público do \textit{IMDB}, que se encontram disponíveis em: 
	\begin{center}
		\textit{\url{https://www.imdb.com/interfaces/}}
	\end{center}

	Ao longo deste documento vão também ser expostos todos os passos tomados durante a implementação das tarefas pedidas neste projeto, incluindo as decisões tomadas pelos elementos deste grupo a nível de algoritmos e parâmetros de configuração.
	Para além disso são ainda apresentadas todas as instruções que permitem executar e utilizar corretamente os programas desenvolvidos.
	Por fim, na fase final deste manuscrito, são exibidos os objetivos atingidos após a realização das tarefas propostas.

	De salientar ainda que durante os capítulos que se seguem são identificadas algumas alternativas para concretizar as tarefas indicadas neste trabalho prático.
}

\chapter{Implementação}
\large {
	Tal como foi enunciado anteriormente, neste projeto é globalmente solicitada a elaboração de duas tarefas. Apresentam-se de seguida as mesmas:
	\begin{enumerate}
		\item Carregar os dados do ficheiro \textit{"title.basics.tsv.gz"} para uma tabela \textit{HBase};
		\item Utilizando a tabela \textit{HBase} do ponto acima e os restantes ficheiros presentes no \textit{dataset} mencionado no capítulo anterior, computar os dados necessários para apresentar para cada ator uma página. Esta última deve conter:
		\begin{itemize}
			\item nome, datas de nascimento e morte;
			\item número total de filmes em que participou como ator;
			\item títulos dos três filmes com melhor cotação em que participou.
		\end{itemize}
		Estes dados devem ser armazenados numa tabela \textit{HBase}.
	\end{enumerate}
	
	Nas próximas secções são evidenciadas as implementações para cada uma destas tarefas bem como algumas sugestões alternativas que poderiam ser tomadas em consideração.
	\section{1ª Tarefa} \label{job1}
		Após descarregar o ficheiro \textit{"title.basics.tsv.gz"} presente na hiperligação do capítulo anterior, dá-se início à execução da sequência de passos descrita nos próximos subcapítulos.
		Antes de observar os passos tomados, é importante salientar que a execução das soluções elaboradas nas secções \hyperref[job1-1]{2.1.1} e \hyperref[job1-3]{2.1.3} são efetuadas com recurso a um ficheiro denominado por \textit{Dockerfile}. De forma a entender melhor a configuração do mesmo, revela-se a seguir o seu conteúdo:
		{
			\color{teal}
            \begin{verbatim}
			    FROM bde2020/hadoop-base
			    COPY target/TP1-1.0-SNAPSHOT.jar /
			    ENTRYPOINT ["hadoop", "jar", "/TP1-1.0-SNAPSHOT.jar", "ClassName"]
			\end{verbatim}
        }
        
        Após esta observação, indica-se ainda as opções adotadas para a execução do ficheiro \textit{Dockerfile} com o intuito de garantir uma execução válida das soluções implementadas:
        {
            \color{teal}
            \begin{verbatim}
			    --network docker-hbase_default
			    --env-file ../docker-hbase/hadoop.env
			    --env-file ../docker-hbase/hbase-distributed-local.env
            \end{verbatim}
        }
		
		\subsection{Criação da tabela \textit{HBase}} \label{job1-1}
		De forma a criar a tabela \textit{HBase} intrínseca a esta tarefa, foi implementada uma classe \textit{Java}, \textbf{\textit{CreateTableMovies}}, que, após conectar-se com a base de dados não relacional \textit{HBase}, trata da sua criação e configuração.
		Durante esse processo, é produzida apenas uma família de colunas, intitulada por \textbf{\textit{details}}, onde será armazenada toda a informação associada aos dados do ficheiro \textit{"title.basics.tsv.gz"}.

		De notar também que atribuiu-se o nome \textbf{\textit{movies}} à tabela gerada, tal como o nome da classe \textit{Java} transparece.

		Foi também criada uma classe \textit{Java} adicional, \textbf{\textit{DeleteTableMovies}}, que trata de eliminar a tabela descrita anteriormente. Esta foi desenvolvida com o intuito de remover a tabela em causa caso esta deixe se ser necessária no futuro.
        
        Apresenta-se de seguida o modelo da tabela \textit{HBase} pretendido para a concretização desta tarefa:
        \begin{figure}[h]
            \centering
            \includegraphics[width=1.0\textwidth]{Imagens/Tabela Hbase.png}
            \caption{Modelo da tabela \textit{HBase}}
            \label{figure1}
        \end{figure}

		\subsubsection{Alternativa}
		Uma possibilidade válida para efetuar todo o processo mencionado acima seria utilizar a \textit{HBase shell} de forma direta. Exibe-se de seguida a respetiva instrução:
        {
            \color{teal}
            \begin{verbatim}
			    docker run -it --network docker-hbase_default
			    --env-file docker-hbase/hbase-distributed-local.env
			    bde2020/hbase-base hbase shell
            \end{verbatim}
        }
        {
			\color{teal}
			\begin{Verbatim}[commandchars=\\\{\}]
	    \textcolor{orange}{hbase(main):001:0>} create "movies", "details"
			\end{Verbatim}
		}

		\subsection{Transferêncía do ficheiro para a plataforma \textit{Hadoop HDFS}} \label{job1-2}
		De maneira a proceder ao carregamento do ficheiro \textit{"title.basics.tsv.gz"} para a plataforma \textit{Hadoop HDFS} existem duas possibilidades. Antes de exibir estas últimas alternativas, foi criada uma pasta na plataforma \textit{Hadoop HDFS}, denominada por \textit{data}, onde serão colocados todos os ficheiros de \textit{input} necessários. Exibe-se de seguida a instrução para tal efeito:
		{
			\color{teal}
			\begin{verbatim}
			    docker run --network docker-hbase_default --env-file 
			    docker-hbase/hadoop.env bde2020/hadoop-base hdfs dfs -mkdir /data
			\end{verbatim}
		}

		Após a exposição deste comando, destacam-se nos próximos subcapítulos as duas alternativas mencionadas acima.

		{
			\color{red}
			\textbf{Discutir o formato do \textit{input} utilizado !!!}
		}
		\subsubsection{1ª Alternativa}
		Nesta possibilidade evidencia-se o campo \texttt{source} que corresponde à diretoria da pasta que contém o ficheiro \textit{"title.basics.tsv.gz"}.
		Dito isto, apresenta-se agora a primeira alternativa:
		{
			\color{teal}
			\begin{verbatim}
			    docker run --network docker-hbase_default --env-file
			    docker-hbase/hadoop.env --mount 
			    type=bind,source="/path/to/local/folder/data",target=/data
			    bde2020/hadoop-base hdfs dfs -put /data/title.basics.tsv.gz /data
			\end{verbatim}
		}

		\subsubsection{2ª Alternativa}
		Esta opção corresponde ao modo interativo de execução disponibilizado pela instrução \textit{docker run}.
		Uma vez feita esta observação, expõe-se a seguir a segunda alternativa:
		{
			\color{teal}
			\begin{verbatim}
			    docker run --network docker-hbase_default --env-file
			    docker-hbase/hadoop.env -it  bde2020/hadoop-base bash

			    curl https://datasets.imdbws.com/title.basics.tsv.gz | gunzip 
			    | hdfs dfs -put - hdfs://namenode:9000/data/title.basics.tsv
			\end{verbatim}
		}

		\subsection{População da tabela \textit{HBase}} \label{job1-3}
		Quanto à população da tabela criada previamente foi igualmente implementada uma classe \textit{Java} para o efeito, designada por \textbf{\textit{PopulateTableMovies}}.
		Esta classe incorpora uma tarefa assente no paradigma \textit{MapReduce}, onde é apenas elaborada a fase de \textit{map}.
		Nessa mesma etapa é processada cada linha do ficheiro de \textit{input} presente na plataforma \textit{Hadoop HDFS} e, quando o tratamento estiver concluído, o resultado obtido é colocado na tabela \textit{movies}.

	\section{2ª Tarefa} \label{job2}
		\subsection{}
		\subsubsection{}
}

\chapter{Conclusão}
\large{
	
}

\appendix
\chapter{Observações}
\begin{itemize}
    \item Documentação \textit{Java} 8:
    \par \textit{\url{https://docs.oracle.com/javase/8/docs/api/}}
	\item \textit{Maven}:
    \par \textit{\url{https://maven.apache.org/}}
    \item \textit{Hadoop}:
    \par \textit{\url{https://hadoop.apache.org/}}
    \item \textit{HBase}:
    \par \textit{\url{https://hbase.apache.org/}}
\end{itemize}


\end{document}